{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 11539512,
          "sourceType": "datasetVersion",
          "datasetId": 7236744
        },
        {
          "sourceId": 11819220,
          "sourceType": "datasetVersion",
          "datasetId": 7423940
        }
      ],
      "dockerImageVersionId": 31011,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "wandb.login(key=\"580e769ee2f34eafdded556ce52aaf31c265ad3b\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T14:05:27.224161Z",
          "iopub.execute_input": "2025-05-20T14:05:27.224467Z",
          "iopub.status.idle": "2025-05-20T14:05:41.233844Z",
          "shell.execute_reply.started": "2025-05-20T14:05:27.224440Z",
          "shell.execute_reply": "2025-05-20T14:05:41.233066Z"
        },
        "id": "-GTh1AWNVXiQ",
        "outputId": "17a7d0c5-905c-4ebb-f6b0-077fc10eaa66"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\nRequirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\nRequirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\nRequirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\nRequirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.7)\nRequirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.20.3)\nRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (7.0.0)\nRequirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.11.3)\nRequirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\nRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\nRequirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.21.0)\nRequirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\nRequirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.13.1)\nRequirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.1 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.33.1)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mma23m011\u001b[0m (\u001b[33mma23m011-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
          "output_type": "stream"
        },
        {
          "execution_count": 1,
          "output_type": "execute_result",
          "data": {
            "text/plain": "True"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Attention"
      ],
      "metadata": {
        "id": "vLJA0TR1VXiS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch  #  for building and training deep learning models\n",
        "import torch.nn as nn  # Imports the neural network module\n",
        "import torch.optim as optim  # Imports optimization algorithms like SGD, Adam, etc.\n",
        "import wandb  # Imports Weights & Biases for experiment tracking (like loss curves, metrics, etc.)\n",
        "from torch.utils.data import Dataset, DataLoader  # Used for creating custom datasets and loading them in batches\n",
        "from sklearn.model_selection import train_test_split  # Used to split the data into training and testing sets\n",
        "import pandas as pd  # Imports pandas library for handling tabular data (like Excel or CSV files)\n",
        "\n",
        "\n",
        "#  Dataset\n",
        "class TransliterationDataset(Dataset):\n",
        "    def __init__(self, data, src_vocab, tgt_vocab):\n",
        "        self.data = data  # Save the input data (list of (src, tgt) pairs)\n",
        "        self.src_vocab = src_vocab  # Save the source vocabulary (dictionary of tokens to numbers)\n",
        "        self.tgt_vocab = tgt_vocab  # Save the target vocabulary\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)# Return the number of samples in the data\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        src, tgt = self.data[idx]# Get one pair of source and target using the index\n",
        "        # for c in src:\n",
        "        #     print(c)\n",
        "        # Convert source text to numbers (IDs), add <sos> at start and <eos> at end\n",
        "        src_ids = [self.src_vocab['<sos>']] + [self.src_vocab.get(c, self.src_vocab['<unk>']) for c in src] + [self.src_vocab['<eos>']]\n",
        "\n",
        "       # Convert target text to numbers (IDs), add <sos> at start and <eos> at end\n",
        "        tgt_ids = [self.tgt_vocab['<sos>']] + [self.tgt_vocab.get(c, self.tgt_vocab['<unk>']) for c in tgt] + [self.tgt_vocab['<eos>']]\n",
        "\n",
        "        return torch.tensor(src_ids), torch.tensor(tgt_ids)  # Return tensors of source and target IDs\n",
        "def collate_fn(batch):\n",
        "    src_seqs, tgt_seqs = zip(*batch)  # Separate source and target sequences in the batch\n",
        "    # Pad all source sequences to the same length with 0 (for batch processing)\n",
        "    src_padded = nn.utils.rnn.pad_sequence(src_seqs, batch_first=True, padding_value=0)\n",
        "    # Pad all target sequences to the same length with 0\n",
        "    tgt_padded = nn.utils.rnn.pad_sequence(tgt_seqs, batch_first=True, padding_value=0)\n",
        "    return src_padded, tgt_padded  # Return the padded sequences\n",
        "\n",
        "\n",
        "\n",
        "# Function to build vocabulary from data\n",
        "def build_vocab(data):\n",
        "    # Start with special tokens in the vocabulary\n",
        "    vocab = {'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3}\n",
        "    idx = 4  # Next available index\n",
        "\n",
        "    for word in data:\n",
        "        if isinstance(word, str):  # Check if the input is a string\n",
        "            for char in word:  # Go through each character\n",
        "                if char not in vocab:  # If character is new\n",
        "                    vocab[char] = idx  # Add it to the vocab\n",
        "                    idx += 1  # Move to next index\n",
        "    return vocab  # Return the final vocabulary\n",
        "\n",
        "\n",
        "class Seq2Seq(nn.Module):  # Define a sequence-to-sequence model using PyTorch\n",
        "    def __init__(self, config, src_vocab_size, tgt_vocab_size):  # Constructor with config and vocab sizes\n",
        "        super().__init__()  # Call the parent class constructor\n",
        "        self.config = config  # Store the configuration\n",
        "\n",
        "        # Create embedding layer for source language with padding index 0\n",
        "        self.embedding_src = nn.Embedding(src_vocab_size, config['embedding_dim'], padding_idx=0)\n",
        "        # Create embedding layer for target language with padding index 0\n",
        "        self.embedding_tgt = nn.Embedding(tgt_vocab_size, config['embedding_dim'], padding_idx=0)\n",
        "\n",
        "        # Choose RNN type (RNN, GRU, or LSTM) based on config\n",
        "        rnn_cell = {'RNN': nn.RNN, 'GRU': nn.GRU, 'LSTM': nn.LSTM}[config['cell_type']]\n",
        "\n",
        "        # Create encoder RNN with config values\n",
        "        self.encoder = rnn_cell(config['embedding_dim'], config['hidden_size'], config['encoder_layers'], dropout=config['dropout'], batch_first=True)\n",
        "        # Create decoder RNN with config values\n",
        "        self.decoder = rnn_cell(config['embedding_dim'], config['hidden_size'], config['decoder_layers'], dropout=config['dropout'], batch_first=True)\n",
        "\n",
        "        # Final fully connected layer to map RNN output to target vocabulary\n",
        "        self.fc_out = nn.Linear(config['hidden_size'], tgt_vocab_size)\n",
        "\n",
        "    def forward(self, src, tgt):  # Forward pass: takes source and target sequences\n",
        "        embedded_src = self.embedding_src(src)  # Get embeddings for source input\n",
        "        embedded_tgt = self.embedding_tgt(tgt)  # Get embeddings for target input\n",
        "\n",
        "        _, hidden = self.encoder(embedded_src)  # Pass source through encoder, get final hidden state\n",
        "\n",
        "        def expand_hidden(h_enc, required_layers):  # Helper function to adjust hidden state layers\n",
        "            # h_enc: (num_layers_enc, batch, hidden_size)\n",
        "            num_enc_layers = h_enc.size(0)  # Get number of encoder layers\n",
        "            if num_enc_layers < required_layers:  # If encoder has fewer layers than decoder\n",
        "                # Create extra zero layers to match decoder requirement\n",
        "                extra = torch.zeros(\n",
        "                    required_layers - num_enc_layers,\n",
        "                    h_enc.size(1),\n",
        "                    h_enc.size(2),\n",
        "                    device=h_enc.device,\n",
        "                    dtype=h_enc.dtype\n",
        "                )\n",
        "                h_enc = torch.cat([h_enc, extra], dim=0)  # Combine original and extra layers\n",
        "            else:\n",
        "                h_enc = h_enc[-required_layers:]  # Take only the needed layers if more\n",
        "            return h_enc  # Return adjusted hidden state\n",
        "\n",
        "        if isinstance(hidden, tuple):  # If RNN is LSTM, hidden is a tuple (h, c)\n",
        "            h, c = hidden  # Split hidden and cell states\n",
        "            h = expand_hidden(h, self.config['decoder_layers'])  # Adjust hidden state\n",
        "            c = expand_hidden(c, self.config['decoder_layers'])  # Adjust cell state\n",
        "            decoder_output, _ = self.decoder(embedded_tgt, (h, c))  # Pass through decoder\n",
        "        else:  # If RNN is GRU or simple RNN\n",
        "            hidden = expand_hidden(hidden, self.config['decoder_layers'])  # Adjust hidden state\n",
        "            decoder_output, _ = self.decoder(embedded_tgt, hidden)  # Pass through decoder\n",
        "\n",
        "        output = self.fc_out(decoder_output)  # Pass decoder output through final layer\n",
        "        return output  # Return the model output\n",
        "\n",
        "\n",
        "\n",
        "# Function to calculate token-level accuracy\n",
        "def calculate_accuracy(output, target, pad_idx):\n",
        "    preds = output.argmax(2)  # Get the predicted token indices with highest probability\n",
        "    mask = (target != pad_idx)  # Create a mask to ignore padding tokens\n",
        "    correct = (preds == target) & mask  # Count only the correct predictions (excluding padding)\n",
        "    return correct.sum().item() / mask.sum().item()  # Return the ratio of correct tokens\n",
        "\n",
        "# Function to calculate word-level (sequence-level) accuracy\n",
        "def compute_word_accuracy(output, target, tgt_index_to_token, pad_idx):\n",
        "    preds = output.argmax(dim=2)  # Get predicted token indices for each position\n",
        "\n",
        "    correct = 0  # Count of correct sequences\n",
        "    total = 0    # Total number of sequences\n",
        "\n",
        "    # Loop over each predicted and target sequence pair\n",
        "    for pred_seq, tgt_seq in zip(preds, target):\n",
        "        # Convert predicted token indices to words/tokens, ignoring padding\n",
        "        pred_tokens = [tgt_index_to_token[idx.item()] for idx in pred_seq if idx.item() != pad_idx]\n",
        "        # Convert target token indices to words/tokens, ignoring padding\n",
        "        tgt_tokens = [tgt_index_to_token[idx.item()] for idx in tgt_seq if idx.item() != pad_idx]\n",
        "\n",
        "        # Cut off predicted tokens after the <eos> token if it exists\n",
        "        if '<eos>' in pred_tokens:\n",
        "            pred_tokens = pred_tokens[:pred_tokens.index('<eos>')]\n",
        "        # Cut off target tokens after the <eos> token if it exists\n",
        "        if '<eos>' in tgt_tokens:\n",
        "            tgt_tokens = tgt_tokens[:tgt_tokens.index('<eos>')]\n",
        "\n",
        "        # If predicted and target token lists are the same, count it as correct\n",
        "        if pred_tokens == tgt_tokens:\n",
        "            correct += 1\n",
        "        total += 1  # Increase total count\n",
        "\n",
        "    # Return the ratio of completely correct sequences\n",
        "    return correct / total if total > 0 else 0.0\n",
        "\n",
        "\n",
        "\n",
        "# Function to train the model\n",
        "def train(model, dataloader, optimizer, criterion, tgt_pad_idx, tgt_index_to_token):\n",
        "    model.train()  # Set model to training mode\n",
        "    total_loss, total_acc, total_word_acc = 0, 0, 0  # Initialize total metrics\n",
        "\n",
        "    for src, tgt in dataloader:  # Loop through each batch\n",
        "        src, tgt = src.to(device), tgt.to(device)  # Move data to GPU or CPU\n",
        "        optimizer.zero_grad()  # Clear old gradients\n",
        "\n",
        "        output = model(src, tgt[:, :-1])  # Predict next tokens using input except last\n",
        "        loss = criterion(output.reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))  # Calculate loss\n",
        "\n",
        "        acc = calculate_accuracy(output, tgt[:, 1:], tgt_pad_idx)  # Token-level accuracy\n",
        "        word_acc = compute_word_accuracy(output, tgt[:, 1:], tgt_index_to_token, tgt_pad_idx)  # Sentence-level accuracy\n",
        "\n",
        "        loss.backward()  # Backpropagation\n",
        "        optimizer.step()  # Update model weights\n",
        "\n",
        "        total_loss += loss.item()  # Add batch loss\n",
        "        total_acc += acc  # Add batch accuracy\n",
        "        total_word_acc += word_acc  # Add batch word accuracy\n",
        "\n",
        "    # Return average metrics\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader), total_word_acc / len(dataloader)\n",
        "\n",
        "# Function to evaluate the model\n",
        "def evaluate(model, dataloader, criterion, tgt_pad_idx, tgt_index_to_token):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "    total_loss, total_acc, total_word_acc = 0, 0, 0  # Initialize total metrics\n",
        "\n",
        "    with torch.no_grad():  # No gradient calculation\n",
        "        for src, tgt in dataloader:  # Loop through each batch\n",
        "            src, tgt = src.to(device), tgt.to(device)  # Move data to device\n",
        "            output = model(src, tgt[:, :-1])  # Predict next tokens\n",
        "\n",
        "            loss = criterion(output.reshape(-1, output.shape[-1]), tgt[:, 1:].reshape(-1))  # Calculate loss\n",
        "            acc = calculate_accuracy(output, tgt[:, 1:], tgt_pad_idx)  # Token accuracy\n",
        "            word_acc = compute_word_accuracy(output, tgt[:, 1:], tgt_index_to_token, tgt_pad_idx)  # Word accuracy\n",
        "\n",
        "            total_loss += loss.item()  # Add loss\n",
        "            total_acc += acc  # Add token accuracy\n",
        "            total_word_acc += word_acc  # Add word accuracy\n",
        "\n",
        "    # Return average metrics\n",
        "    return total_loss / len(dataloader), total_acc / len(dataloader), total_word_acc / len(dataloader)\n",
        "\n",
        "def sweep_train():  # Function to train with W&B sweep\n",
        "    wandb.init()  # Initialize wandb\n",
        "    config = wandb.config  # Get config from sweep\n",
        "\n",
        "    # Load train dataset\n",
        "    train_df = pd.read_csv(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv\", sep=\"\\t\", header=None, names=[\"tgt\", \"src\", \"freq\"])\n",
        "    # Repeat rows based on frequency\n",
        "    train_df = train_df.loc[train_df.index.repeat(train_df['freq'])].reset_index(drop=True)\n",
        "    # Load dev dataset\n",
        "    dev_df = pd.read_csv(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv\", sep=\"\\t\", header=None, names=[\"tgt\", \"src\", \"freq\"])\n",
        "\n",
        "    # Convert to string\n",
        "    train_df['src'] = train_df['src'].astype(str)\n",
        "    train_df['tgt'] = train_df['tgt'].astype(str)\n",
        "\n",
        "    # Build vocabularies\n",
        "    src_vocab = build_vocab(train_df['src'])\n",
        "    tgt_vocab = build_vocab(train_df['tgt'])\n",
        "\n",
        "    print(src_vocab)  # Print source vocab\n",
        "    print(tgt_vocab)  # Print target vocab\n",
        "\n",
        "    # Index to token mapping\n",
        "    tgt_index_to_token = {v: k for k, v in tgt_vocab.items()}\n",
        "    idx_to_tgt = {v: k for k, v in tgt_vocab.items()}\n",
        "\n",
        "    # Prepare training and dev data\n",
        "    train_data = list(zip(train_df['src'], train_df['tgt']))\n",
        "    dev_data = list(zip(dev_df['src'], dev_df['tgt']))\n",
        "\n",
        "    # Create datasets\n",
        "    train_dataset = TransliterationDataset(train_data, src_vocab, tgt_vocab)\n",
        "    dev_dataset = TransliterationDataset(dev_data, src_vocab, tgt_vocab)\n",
        "\n",
        "    # Create dataloaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Initialize model\n",
        "    model = Seq2Seq(config, len(src_vocab), len(tgt_vocab)).to(device)\n",
        "\n",
        "    # Set optimizer\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # Set loss function\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
        "\n",
        "    # Training loop\n",
        "    for epoch in range(config['epochs']):\n",
        "        # Train model\n",
        "        train_loss, train_acc, train_word_acc = train(model, train_loader, optimizer, criterion, tgt_vocab['<pad>'], tgt_index_to_token)\n",
        "        # Evaluate model\n",
        "        val_loss, val_acc, val_word_acc = evaluate(model, dev_loader, criterion, tgt_vocab['<pad>'], tgt_index_to_token)\n",
        "\n",
        "        # Print metrics\n",
        "        print(f\"Epoch {epoch + 1}\")\n",
        "        print(f\"{'train_loss:':20} {train_loss:.4f}\")\n",
        "        print(f\"{'val_loss:':20} {val_loss:.4f}\")\n",
        "        print(f\"{'train_accuracy:':20} {train_acc * 100:.2f}%\")\n",
        "        print(f\"{'val_accuracy:':20} {val_acc * 100:.2f}%\")\n",
        "        print(f\"{'train_word_accuracy:':20} {train_word_acc * 100:.2f}%\")\n",
        "        print(f\"{'val_word_accuracy:':20} {val_word_acc * 100:.2f}%\")\n",
        "\n",
        "        # Log to wandb\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"train_accuracy\": train_acc * 100,\n",
        "            \"val_accuracy\": val_acc * 100,\n",
        "            \"train_word_accuracy\": train_word_acc * 100,\n",
        "            \"val_word_accuracy\": val_word_acc * 100\n",
        "        })\n",
        "\n",
        "    # predict_and_show(model, dev_dataset, src_vocab, tgt_vocab, idx_to_tgt, num_samples=100)\n",
        "\n",
        "\n",
        "\n",
        "# Set device to GPU if available, else CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define sweep configuration\n",
        "sweep_config = {\n",
        "    'method': 'random',  # Use random search for hyperparameters\n",
        "    'name': 'DakshinaSweepForPred',  # Name of the sweep\n",
        "    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},  # Goal is to maximize validation accuracy\n",
        "    'parameters': {\n",
        "        'embedding_dim': {'values': [32, 64, 128]},  # Try different embedding dimensions\n",
        "        'hidden_size': {'values': [64, 128]},  # Try different hidden sizes\n",
        "        'encoder_layers': {'values': [1, 2, 3]},  # Try 1 to 3 encoder layers\n",
        "        'decoder_layers': {'values': [1, 2, 3]},  # Try 1 to 3 decoder layers\n",
        "        'cell_type': {'values': ['RNN', 'GRU', 'LSTM']},  # Try different RNN cell types\n",
        "        'dropout': {'values': [0.2, 0.3]},  # Try different dropout rates\n",
        "        'epochs': {'values': [5, 10, 13, 15, 17, 20]}  # Try different number of epochs\n",
        "    }\n",
        "}\n",
        "\n",
        "# Create sweep with the above config and project name\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"DL_A3\")\n",
        "\n",
        "# Run the sweep agent for one configuration using sweep_train function\n",
        "wandb.agent(sweep_id, function=sweep_train, count=1)\n"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T14:05:44.378290Z",
          "iopub.execute_input": "2025-05-20T14:05:44.378772Z",
          "iopub.status.idle": "2025-05-20T14:05:49.806721Z",
          "shell.execute_reply.started": "2025-05-20T14:05:44.378745Z",
          "shell.execute_reply": "2025-05-20T14:05:49.805961Z"
        },
        "id": "9r9uolRcVXiT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Without Attention: Predict with beam search"
      ],
      "metadata": {
        "id": "VFQy0UJdVXiU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define function to predict using beam search\n",
        "def predict_with_beam_search(model, src_seq, src_vocab, tgt_vocab, beam_width=3, max_len=30):\n",
        "    model.eval()  # Set model to evaluation mode\n",
        "\n",
        "    sos_token = tgt_vocab['<sos>']  # Start of sequence token\n",
        "    eos_token = tgt_vocab['<eos>']  # End of sequence token\n",
        "    pad_token = tgt_vocab['<pad>']  # Padding token\n",
        "\n",
        "    tgt_index_to_token = {v: k for k, v in tgt_vocab.items()}  # Map indices to tokens\n",
        "\n",
        "    with torch.no_grad():  # Disable gradient calculation\n",
        "        # Convert input string to tensor of indices with <sos> and <eos>\n",
        "        src_seq = torch.tensor(\n",
        "            [src_vocab['<sos>']] + [src_vocab.get(c, src_vocab['<unk>']) for c in src_seq] + [src_vocab['<eos>']]\n",
        "        ).unsqueeze(0).to(device)  # Add batch dimension and move to device\n",
        "\n",
        "        embedded_src = model.embedding_src(src_seq)  # Embed the source sequence\n",
        "        encoder_output, hidden = model.encoder(embedded_src)  # Pass through encoder\n",
        "\n",
        "        # Handle LSTM hidden state\n",
        "        if isinstance(hidden, tuple):\n",
        "            h, c = hidden  # For LSTM: hidden = (h, c)\n",
        "        else:\n",
        "            h, c = hidden, None  # For RNN/GRU: no c state\n",
        "\n",
        "        # Get number of expected decoder layers\n",
        "        expected_layers = model.config.get(\"decoder_num_layers\", 3)\n",
        "        actual_layers = h.shape[0]  # Actual number of layers in hidden state\n",
        "\n",
        "        # If decoder expects more layers than encoder provided\n",
        "        if actual_layers < expected_layers:\n",
        "            diff = expected_layers - actual_layers  # Number of missing layers\n",
        "            extra_h = torch.zeros(diff, h.shape[1], h.shape[2], device=h.device)  # Create extra h layers\n",
        "            h = torch.cat([h, extra_h], dim=0)  # Concatenate extra layers\n",
        "\n",
        "            if c is not None:\n",
        "                extra_c = torch.zeros(diff, c.shape[1], c.shape[2], device=c.device)  # Create extra c layers\n",
        "                c = torch.cat([c, extra_c], dim=0)  # Concatenate extra c layers\n",
        "\n",
        "        # Initialize beams with start token and zero score\n",
        "        beams = [(torch.tensor([sos_token], device=device), 0.0, h, c)]\n",
        "\n",
        "        for _ in range(max_len):  # Loop until max length\n",
        "            new_beams = []  # Store new candidate beams\n",
        "            for seq, score, h, c in beams:  # Iterate over current beams\n",
        "                if seq[-1].item() == eos_token:  # If sequence ends with <eos>\n",
        "                    new_beams.append((seq, score, h, c))  # Keep it as is\n",
        "                    continue\n",
        "\n",
        "                # Get embedding for last predicted token\n",
        "                embedded = model.embedding_tgt(seq[-1].unsqueeze(0).unsqueeze(0))\n",
        "\n",
        "                # Pass through decoder based on cell type\n",
        "                if model.config['cell_type'] == 'LSTM':\n",
        "                    output, (h_new, c_new) = model.decoder(embedded, (h, c))  # For LSTM\n",
        "                else:\n",
        "                    output, h_new = model.decoder(embedded, h)  # For RNN/GRU\n",
        "                    c_new = None\n",
        "\n",
        "                logits = model.fc_out(output.squeeze(1))  # Compute output logits\n",
        "                log_probs = torch.log_softmax(logits, dim=-1).squeeze(0)  # Get log probabilities\n",
        "\n",
        "                # Get top k predictions\n",
        "                topk_log_probs, topk_indices = torch.topk(log_probs, beam_width)\n",
        "\n",
        "                # Create new beams with each top prediction\n",
        "                for log_prob, idx in zip(topk_log_probs, topk_indices):\n",
        "                    new_seq = torch.cat([seq, idx.unsqueeze(0)])  # Append predicted token\n",
        "                    new_score = score + log_prob.item()  # Update beam score\n",
        "                    new_beams.append((new_seq, new_score, h_new, c_new))  # Add new beam\n",
        "\n",
        "            # Keep top beam_width beams\n",
        "            beams = sorted(new_beams, key=lambda x: x[1], reverse=True)[:beam_width]\n",
        "\n",
        "        best_seq = beams[0][0]  # Get best predicted sequence\n",
        "\n",
        "        # Convert indices to tokens, skip <pad> and <eos>\n",
        "        return ''.join([tgt_index_to_token[token.item()] for token in best_seq[1:] if token.item() not in [pad_token, eos_token]])\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T14:05:49.808049Z",
          "iopub.execute_input": "2025-05-20T14:05:49.808526Z",
          "iopub.status.idle": "2025-05-20T14:05:49.821239Z",
          "shell.execute_reply.started": "2025-05-20T14:05:49.808502Z",
          "shell.execute_reply": "2025-05-20T14:05:49.820295Z"
        },
        "id": "zXbkuNZMVXiU"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "# def predict_and_show(model, dataset, src_vocab, tgt_vocab, idx_to_tgt, num_samples=10):\n",
        "#     model.eval()\n",
        "#     dataloader = DataLoader(dataset, batch_size=1, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "#     sos_idx = tgt_vocab['<sos>']\n",
        "#     eos_idx = tgt_vocab['<eos>']\n",
        "#     pad_idx = tgt_vocab['<pad>']\n",
        "\n",
        "#     for i, (src_tensor, tgt_tensor) in enumerate(dataloader):\n",
        "#         if i >= num_samples:\n",
        "#             break\n",
        "\n",
        "#         src_tensor = src_tensor.to(device)\n",
        "#         tgt_tensor = tgt_tensor.to(device)\n",
        "\n",
        "#         with torch.no_grad():\n",
        "#             output = model(src_tensor, tgt_tensor[:, :-1])\n",
        "\n",
        "#         # Get predicted token indices\n",
        "#         pred_tokens = output.argmax(dim=2)[0].tolist()\n",
        "\n",
        "#         # Convert indices to tokens, removing padding and after <eos>\n",
        "#         input_tokens = [k for k,v in src_vocab.items() if v in src_tensor[0].tolist()]\n",
        "#         actual_tokens = [idx_to_tgt[idx.item()] for idx in tgt_tensor[0] if idx.item() not in [sos_idx, eos_idx, pad_idx]]\n",
        "#         predicted_tokens = []\n",
        "#         for idx in pred_tokens:\n",
        "#             if idx == eos_idx:\n",
        "#                 break\n",
        "#             if idx not in [sos_idx, pad_idx]:\n",
        "#                 predicted_tokens.append(idx_to_tgt.get(idx, '?'))\n",
        "\n",
        "#         # Print the result\n",
        "#         input_text = ''.join([k for k,v in src_vocab.items() if v in src_tensor[0].tolist() and v not in [sos_idx, eos_idx, pad_idx]])\n",
        "#         print(\"Input text:     \", input_text)\n",
        "#         print(\"Actual text:    \", ''.join(actual_tokens))\n",
        "#         print(\"Predicted text: \", ''.join(predicted_tokens))\n",
        "#         print(\"-\" * 30)\n",
        "\n",
        "\n",
        "def sweep_train_pred():\n",
        "    wandb.init()  # Initialize a new Weights and Biases (wandb) run\n",
        "    config = wandb.config  # Access configuration parameters from wandb\n",
        "\n",
        "    # Load training dataset and assign column names\n",
        "    train_df = pd.read_csv(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.train.tsv\", sep=\"\\t\", header=None, names=[\"tgt\", \"src\", \"freq\"])\n",
        "\n",
        "    # Repeat rows in training data according to frequency\n",
        "    train_df = train_df.loc[train_df.index.repeat(train_df['freq'])].reset_index(drop=True)\n",
        "\n",
        "    # Load validation/dev dataset\n",
        "    dev_df = pd.read_csv(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.dev.tsv\", sep=\"\\t\", header=None, names=[\"tgt\", \"src\", \"freq\"])\n",
        "\n",
        "    # Load test dataset\n",
        "    test_df = pd.read_csv(\"/kaggle/input/dakshina/dakshina_dataset_v1.0/bn/lexicons/bn.translit.sampled.test.tsv\", sep=\"\\t\", header=None, names=[\"tgt\", \"src\", \"freq\"])\n",
        "\n",
        "    # Ensure src and tgt columns in training data are strings\n",
        "    train_df['src'] = train_df['src'].astype(str)\n",
        "    train_df['tgt'] = train_df['tgt'].astype(str)\n",
        "\n",
        "    # Build vocabulary for source language\n",
        "    src_vocab = build_vocab(train_df['src'])\n",
        "\n",
        "    # Build vocabulary for target language\n",
        "    tgt_vocab = build_vocab(train_df['tgt'])\n",
        "\n",
        "    # Print source vocabulary\n",
        "    print(src_vocab)\n",
        "\n",
        "    # Print target vocabulary\n",
        "    print(tgt_vocab)\n",
        "\n",
        "    # Map target vocabulary index to token\n",
        "    tgt_index_to_token = {v: k for k, v in tgt_vocab.items()}\n",
        "\n",
        "    # Duplicate mapping of index to target token\n",
        "    idx_to_tgt = {v: k for k, v in tgt_vocab.items()}\n",
        "\n",
        "    # Create training data as (src, tgt) pairs\n",
        "    train_data = list(zip(train_df['src'], train_df['tgt']))\n",
        "\n",
        "    # Create validation data as (src, tgt) pairs\n",
        "    dev_data = list(zip(dev_df['src'], dev_df['tgt']))\n",
        "\n",
        "    # Create test data as (src, tgt) pairs\n",
        "    test_data = list(zip(test_df['src'], test_df['tgt']))\n",
        "\n",
        "    # Create training dataset object\n",
        "    train_dataset = TransliterationDataset(train_data, src_vocab, tgt_vocab)\n",
        "\n",
        "    # Create validation dataset object\n",
        "    dev_dataset = TransliterationDataset(dev_data, src_vocab, tgt_vocab)\n",
        "\n",
        "    # Create test dataset object\n",
        "    test_dataset = TransliterationDataset(test_data, src_vocab, tgt_vocab)\n",
        "\n",
        "    # Create DataLoader for training dataset\n",
        "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "\n",
        "    # Create DataLoader for validation dataset\n",
        "    dev_loader = DataLoader(dev_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Create DataLoader for test dataset\n",
        "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "    # Instantiate Seq2Seq model and move it to device (GPU/CPU)\n",
        "    model = Seq2Seq(config, len(src_vocab), len(tgt_vocab)).to(device)\n",
        "\n",
        "    # Define Adam optimizer\n",
        "    optimizer = optim.Adam(model.parameters())\n",
        "\n",
        "    # Define cross-entropy loss, ignoring padding token\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=tgt_vocab['<pad>'])\n",
        "\n",
        "    # Loop over epochs for training\n",
        "    for epoch in range(config['epochs']):\n",
        "        # Train the model and get training metrics\n",
        "        train_loss, train_acc, train_word_acc = train(model, train_loader, optimizer, criterion, tgt_vocab['<pad>'], tgt_index_to_token)\n",
        "\n",
        "        # Evaluate model on validation data\n",
        "        val_loss, val_acc, val_word_acc = evaluate(model, dev_loader, criterion, tgt_vocab['<pad>'], tgt_index_to_token)\n",
        "\n",
        "        # Evaluate model on test data\n",
        "        test_loss, test_acc, test_word_acc = evaluate(model, test_loader, criterion, tgt_vocab['<pad>'], tgt_index_to_token)\n",
        "\n",
        "        # Print metrics for this epoch\n",
        "        print(f\"Epoch {epoch + 1}\")\n",
        "        print(f\"{'train_loss:':20} {train_loss:.4f}\")\n",
        "        print(f\"{'val_loss:':20} {val_loss:.4f}\")\n",
        "        print(f\"{'test_loss:':20} {test_loss:.4f}\")\n",
        "        print(f\"{'train_accuracy:':20} {train_acc * 100:.2f}%\")\n",
        "        print(f\"{'val_accuracy:':20} {val_acc * 100:.2f}%\")\n",
        "        print(f\"{'test_accuracy:':20} {test_acc * 100:.2f}%\")\n",
        "        print(f\"{'train_word_accuracy:':20} {train_word_acc * 100:.2f}%\")\n",
        "        print(f\"{'val_word_accuracy:':20} {val_word_acc * 100:.2f}%\")\n",
        "        print(f\"{'test_word_accuracy:':20} {test_word_acc * 100:.2f}%\")\n",
        "\n",
        "        # Log metrics to Weights & Biases\n",
        "        wandb.log({\n",
        "            \"epoch\": epoch + 1,\n",
        "            \"train_loss\": train_loss,\n",
        "            \"val_loss\": val_loss,\n",
        "            \"test_loss\": test_loss,\n",
        "            \"train_accuracy\": train_acc * 100,\n",
        "            \"val_accuracy\": val_acc * 100,\n",
        "            \"test_accuracy\": test_acc * 100,\n",
        "            \"train_word_accuracy\": train_word_acc * 100,\n",
        "            \"val_word_accuracy\": val_word_acc * 100,\n",
        "            \"test_word_accuracy\": test_word_acc * 100\n",
        "        })\n",
        "\n",
        "    # Get beam width value from config (used in beam search decoding)\n",
        "    beam_width = config.get('beam_width')\n",
        "    print('beam_width', beam_width)\n",
        "\n",
        "    # Initialize list to store prediction results\n",
        "    results = []\n",
        "\n",
        "    # Loop over test samples for prediction\n",
        "    for sample_src, actual_tgt in test_data[:9229]:\n",
        "        # Generate prediction using beam search\n",
        "        pred_seq = predict_with_beam_search(model, sample_src, src_vocab, tgt_vocab, beam_width=beam_width)\n",
        "\n",
        "        # Remove special tokens from prediction\n",
        "        pred_tokens = [c for c in pred_seq if c not in ['<sos>', '<pad>', '<eos>']]\n",
        "\n",
        "        # Join predicted tokens to form final string\n",
        "        pred_str = ''.join(pred_tokens)\n",
        "\n",
        "        # Print input, actual, and predicted strings\n",
        "        print(f\"Input:      {sample_src}\")\n",
        "        print(f\"Actual:     {actual_tgt}\")\n",
        "        print(f\"Prediction: {pred_str}\")\n",
        "        print(\"-\" * 30)\n",
        "\n",
        "        # Add the result to results list\n",
        "        results.append({\n",
        "            \"Input\": sample_src,\n",
        "            \"Actual\": actual_tgt,\n",
        "            \"Prediction\": pred_str\n",
        "        })\n",
        "\n",
        "    # Define output CSV path\n",
        "    output_csv_path = \"beam_search_predictions.csv\"\n",
        "\n",
        "    # Save all results to a CSV file\n",
        "    with open(output_csv_path, mode='w', encoding='utf-8-sig', newline='') as f:\n",
        "        writer = csv.DictWriter(f, fieldnames=[\"Input\", \"Actual\", \"Prediction\"])\n",
        "        writer.writeheader()\n",
        "        writer.writerows(results)\n",
        "\n",
        "    # Print confirmation message\n",
        "    print(f\"Saved predictions to {output_csv_path}\"\n",
        "\n",
        "# Set the device to GPU if available, otherwise use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Define the sweep configuration for hyperparameter tuning using Weights & Biases\n",
        "sweep_config = {\n",
        "    'method': 'random',  # Use random search to sample hyperparameters\n",
        "    'name': 'DakshinaSweepForPred_Best_without_attn_nothing',  # Name of the sweep\n",
        "    'metric': {'name': 'val_accuracy', 'goal': 'maximize'},  # Target metric to maximize during tuning\n",
        "    'parameters': {  # Define the hyperparameters to sweep\n",
        "        'embedding_dim': {'values': [256]},  # Embedding dimension\n",
        "        'hidden_size': {'values': [128]},  # Hidden size of RNN\n",
        "        'encoder_layers': {'values': [2]},  # Number of layers in encoder\n",
        "        'decoder_layers': {'values': [3]},  # Number of layers in decoder\n",
        "        'cell_type': {'values': ['LSTM']},  # Type of RNN cell to use\n",
        "        'dropout': {'values': [0.3]},  # Dropout rate\n",
        "        'epochs': {'values': [1]},  # Number of epochs to train\n",
        "        'beam_width': {'values': [3]}  # Beam width to use during beam search prediction\n",
        "    }\n",
        "}\n",
        "\n",
        "# Initialize the sweep in Weights & Biases and get the sweep ID\n",
        "sweep_id = wandb.sweep(sweep_config, project=\"DL_A3\")\n",
        "\n",
        "# Start an agent that will run the sweep using the sweep_train_pred function for 1 run\n",
        "wandb.agent(sweep_id, function=sweep_train_pred, count=1)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-05-20T14:05:52.223194Z",
          "iopub.execute_input": "2025-05-20T14:05:52.223926Z",
          "iopub.status.idle": "2025-05-20T14:09:36.107867Z",
          "shell.execute_reply.started": "2025-05-20T14:05:52.223879Z",
          "shell.execute_reply": "2025-05-20T14:09:36.107101Z"
        },
        "id": "fQky8FbAVXiV",
        "outputId": "e14912f4-ea30-4fba-a7fc-96c4a6b298e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Create sweep with ID: 7fce309f\nSweep URL: https://wandb.ai/ma23m011-iit-madras/DL_A3/sweeps/7fce309f\n",
          "output_type": "stream"
        },
        {
          "name": "stderr",
          "text": "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 0wxhv9b3 with config:\n\u001b[34m\u001b[1mwandb\u001b[0m: \tbeam_width: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tcell_type: LSTM\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_layers: 3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.3\n\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_dim: 256\n\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_layers: 2\n\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 1\n\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_size: 128\n\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Tracking run with wandb version 0.19.6"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Run data is saved locally in <code>/kaggle/working/wandb/run-20250520_140559-0wxhv9b3</code>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Syncing run <strong><a href='https://wandb.ai/ma23m011-iit-madras/DL_A3/runs/0wxhv9b3' target=\"_blank\">earnest-sweep-1</a></strong> to <a href='https://wandb.ai/ma23m011-iit-madras/DL_A3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>Sweep page: <a href='https://wandb.ai/ma23m011-iit-madras/DL_A3/sweeps/7fce309f' target=\"_blank\">https://wandb.ai/ma23m011-iit-madras/DL_A3/sweeps/7fce309f</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View project at <a href='https://wandb.ai/ma23m011-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/ma23m011-iit-madras/DL_A3</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View sweep at <a href='https://wandb.ai/ma23m011-iit-madras/DL_A3/sweeps/7fce309f' target=\"_blank\">https://wandb.ai/ma23m011-iit-madras/DL_A3/sweeps/7fce309f</a>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run at <a href='https://wandb.ai/ma23m011-iit-madras/DL_A3/runs/0wxhv9b3' target=\"_blank\">https://wandb.ai/ma23m011-iit-madras/DL_A3/runs/0wxhv9b3</a>"
          },
          "metadata": {}
        },
        {
          "name": "stdout",
          "text": "{'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3, 'a': 4, 'n': 5, 'g': 6, 'k': 7, 'i': 8, 't': 9, 'o': 10, 'e': 11, 'r': 12, 's': 13, 'h': 14, 'y': 15, 'w': 16, 'u': 17, 'l': 18, 'd': 19, 'j': 20, 'b': 21, 'm': 22, 'c': 23, 'q': 24, 'z': 25, 'p': 26, 'x': 27, 'v': 28, 'f': 29}\n{'<pad>': 0, '<sos>': 1, '<eos>': 2, '<unk>': 3, 'অ': 4, 'ং': 5, 'ক': 6, 'ি': 7, 'ত': 8, 'ে': 9, 'র': 10, 'শ': 11, 'ই': 12, 'ও': 13, 'গ': 14, 'ু': 15, 'ল': 16, 'ো': 17, '্': 18, 'হ': 19, 'ণ': 20, 'া': 21, 'ী': 22, 'দ': 23, 'ন': 24, 'ট': 25, 'ব': 26, 'ষ': 27, 'ম': 28, 'স': 29, 'খ': 30, 'য': 31, 'ড': 32, 'ৎ': 33, 'ধ': 34, 'ঠ': 35, 'জ': 36, 'প': 37, 'ূ': 38, 'চ': 39, 'ছ': 40, 'ভ': 41, 'ঘ': 42, 'ঙ': 43, 'ৈ': 44, 'ঞ': 45, '়': 46, 'ঃ': 47, 'এ': 48, 'থ': 49, 'ৃ': 50, 'ৌ': 51, 'ফ': 52, 'ঝ': 53, 'আ': 54, 'উ': 55, 'ঁ': 56, 'ঈ': 57, 'ঊ': 58, 'ঋ': 59, 'ঐ': 60, 'ঔ': 61, 'ঢ': 62, '২': 63}\nEpoch 1\ntrain_loss:          1.4595\nval_loss:            0.7188\ntest_loss:           0.7149\ntrain_accuracy:      58.07%\nval_accuracy:        77.33%\ntest_accuracy:       76.96%\ntrain_word_accuracy: 6.58%\nval_word_accuracy:   17.24%\ntest_word_accuracy:  16.63%\nbeam_width 3\nInput:      angkush\nActual:     অংকুশ\nPrediction: অঙ্কুষ\n------------------------------\nInput:      ankush\nActual:     অংকুশ\nPrediction: অনুক্ষ\n------------------------------\nInput:      ongkush\nActual:     অংকুশ\nPrediction: অঙ্কুষ\n------------------------------\nInput:      onkush\nActual:     অংকুশ\nPrediction: অনুক্ষ\n------------------------------\nInput:      angshogragon\nActual:     অংশগ্রহন\nPrediction: অংশগ্রহণ\n------------------------------\nInput:      angshograhon\nActual:     অংশগ্রহন\nPrediction: অংশগ্রহণ\n------------------------------\nInput:      angshogrohon\nActual:     অংশগ্রহন\nPrediction: অংশগ্রহণ\n------------------------------\nInput:      angsogrohon\nActual:     অংশগ্রহন\nPrediction: অংশগ্রহণ\n------------------------------\nInput:      ongshograhon\nActual:     অংশগ্রহন\nPrediction: অংশগ্রহণ\n------------------------------\nInput:      ongshogrohon\nActual:     অংশগ্রহন\nPrediction: অংশগ্রহণ\n------------------------------\nInput:      angsogrohone\nActual:     অংশগ্রহনের\nPrediction: অংশগ্রহণে\n------------------------------\nInput:      anshograhone\nActual:     অংশগ্রহনের\nPrediction: অংশগ্রহণে\n------------------------------\nInput:      ongshogrohoner\nActual:     অংশগ্রহনের\nPrediction: অংশগ্রহণের\n------------------------------\nInput:      onshogrohoner\nActual:     অংশগ্রহনের\nPrediction: অংশগ্রহণের\n------------------------------\nInput:      akten\nActual:     অকটেন\nPrediction: একতেন\n------------------------------\nInput:      octane\nActual:     অকটেন\nPrediction: অক্তানে\n------------------------------\nInput:      akreetokarjo\nActual:     অকৃতকার্য\nPrediction: আক্রীতারকা\n------------------------------\nInput:      akritakarja\nActual:     অকৃতকার্য\nPrediction: আকৃত্যাকার\n------------------------------\nInput:      akritakarjo\nActual:     অকৃতকার্য\nPrediction: আকৃত্যকার\n------------------------------\nInput:      okritakarja\nActual:     অকৃতকার্য\nPrediction: অকৃত্যাকার\n------------------------------\nInput:      okritakarjo\nActual:     অকৃতকার্য\nPrediction: অকৃত্যাকার\n------------------------------\nInput:      okritokarjo\nActual:     অকৃতকার্য\nPrediction: অকৃত্যাকার\n------------------------------\nInput:      akkhar\nActual:     অক্ষর\nPrediction: আক্ষার\n------------------------------\nInput:      okkhor\nActual:     অক্ষর\nPrediction: অক্ষর\n------------------------------\nInput:      akkharke\nActual:     অক্ষরকে\nPrediction: আক্ষরকে\n------------------------------\nInput:      akkharkey\nActual:     অক্ষরকে\nPrediction: আক্ষরকে\n------------------------------\nInput:      aksharke\nActual:     অক্ষরকে\nPrediction: আক্ষরেক\n------------------------------\nInput:      okkhorke\nActual:     অক্ষরকে\nPrediction: অক্ষরকে\n------------------------------\nInput:      akhhunno\nActual:     অক্ষুণ্ণ\nPrediction: আখুন্ণ\n------------------------------\nInput:      akkhunno\nActual:     অক্ষুণ্ণ\nPrediction: অক্ষণুণ\n------------------------------\nInput:      okhhunno\nActual:     অক্ষুণ্ণ\nPrediction: অখুন্ণ\n------------------------------\nInput:      auxfordey\nActual:     অক্সফোর্ডে\nPrediction: অক্ষার্থে\n------------------------------\nInput:      oxforde\nActual:     অক্সফোর্ডে\nPrediction: অক্সর্জের\n------------------------------\nInput:      oxfordey\nActual:     অক্সফোর্ডে\nPrediction: অক্সর্জের\n------------------------------\nInput:      akhandata\nActual:     অখণ্ডতা\nPrediction: আখানতা\n------------------------------\nInput:      akhandota\nActual:     অখণ্ডতা\nPrediction: আখান্দতা\n------------------------------\nInput:      okhondota\nActual:     অখণ্ডতা\nPrediction: অখনত্য\n------------------------------\nInput:      akhando\nActual:     অখন্ড\nPrediction: আখান্দ\n------------------------------\nInput:      aukhando\nActual:     অখন্ড\nPrediction: আখন্দ\n------------------------------\nInput:      agahir\nActual:     অগভীর\nPrediction: অবাহীর\n------------------------------\nInput:      agovir\nActual:     অগভীর\nPrediction: অগভির\n------------------------------\nInput:      ogobhir\nActual:     অগভীর\nPrediction: অভিবার\n------------------------------\nInput:      ogovir\nActual:     অগভীর\nPrediction: অগভির\n------------------------------\nInput:      augusteen\nActual:     অগাস্টিন\nPrediction: অগুষ্ঠিন\n------------------------------\nInput:      augustin\nActual:     অগাস্টিন\nPrediction: অগুষ্ঠিন\n------------------------------\nInput:      augustine\nActual:     অগাস্টিন\nPrediction: অগুষ্ঠিনে\n------------------------------\nInput:      agradut\nActual:     অগ্রদূত\nPrediction: অগ্রদত\n------------------------------\nInput:      agrodoot\nActual:     অগ্রদূত\nPrediction: অগ্রদত\n------------------------------\nInput:      agrodut\nActual:     অগ্রদূত\nPrediction: অগ্রদুত\n------------------------------\nInput:      ogradut\nActual:     অগ্রদূত\nPrediction: অগ্রদত\n------------------------------\nInput:      ogrodoot\nActual:     অগ্রদূত\nPrediction: অগ্রদত\n------------------------------\nInput:      ogrodut\nActual:     অগ্রদূত\nPrediction: অগ্রদুত\n------------------------------\nInput:      angkita\nActual:     অঙ্কিতা\nPrediction: অঙ্কিতা\n------------------------------\nInput:      ankeeta\nActual:     অঙ্কিতা\nPrediction: অন্কেত\n------------------------------\nInput:      ankita\nActual:     অঙ্কিতা\nPrediction: অন্কিত\n------------------------------\nInput:      ongkita\nActual:     অঙ্কিতা\nPrediction: অঙ্কিতা\n------------------------------\nInput:      onkeeta\nActual:     অঙ্কিতা\nPrediction: অনকেত\n------------------------------\nInput:      onkita\nActual:     অঙ্কিতা\nPrediction: অংকিত\n------------------------------\nInput:      onnkita\nActual:     অঙ্কিতা\nPrediction: অন্যকিত\n------------------------------\nInput:      ajuhat\nActual:     অজুহাত\nPrediction: অধুত\n------------------------------\nInput:      ajuhath\nActual:     অজুহাত\nPrediction: অধুভা\n------------------------------\nInput:      ojuhat\nActual:     অজুহাত\nPrediction: অধুব\n------------------------------\nInput:      anchalo\nActual:     অঞ্চলও\nPrediction: অঞ্চল\n------------------------------\nInput:      auncholo\nActual:     অঞ্চলও\nPrediction: অংখল\n------------------------------\nInput:      oncholo\nActual:     অঞ্চলও\nPrediction: অনচল\n------------------------------\nInput:      anchalke\nActual:     অঞ্চলকে\nPrediction: অঞ্চলকে\n------------------------------\nInput:      anchalkey\nActual:     অঞ্চলকে\nPrediction: অঞ্চলকে\n------------------------------\nInput:      ancholke\nActual:     অঞ্চলকে\nPrediction: অঞ্চলকে\n------------------------------\nInput:      oncholke\nActual:     অঞ্চলকে\nPrediction: অংখলে\n------------------------------\nInput:      anchalgoolir\nActual:     অঞ্চলগুলির\nPrediction: অঞ্চলগুলির\n------------------------------\nInput:      anchalgulir\nActual:     অঞ্চলগুলির\nPrediction: অঞ্চলগুলির\n------------------------------\nInput:      ancholgoolir\nActual:     অঞ্চলগুলির\nPrediction: অঞ্চলগুলীর\n------------------------------\nInput:      ancholgulir\nActual:     অঞ্চলগুলির\nPrediction: অঞ্চলুলিদের\n------------------------------\nInput:      onchalgoolir\nActual:     অঞ্চলগুলির\nPrediction: অংচলালীর\n------------------------------\nInput:      onchalgulir\nActual:     অঞ্চলগুলির\nPrediction: অংচলালীর\n------------------------------\nInput:      oncholgoolir\nActual:     অঞ্চলগুলির\nPrediction: অংচলালীর\n------------------------------\nInput:      oncholgulir\nActual:     অঞ্চলগুলির\nPrediction: অংচললির\n------------------------------\nInput:      anchalgulote\nActual:     অঞ্চলগুলোতে\nPrediction: অঞ্চলগুলোতে\n------------------------------\nInput:      ancholgoolote\nActual:     অঞ্চলগুলোতে\nPrediction: অঞ্চলগুলতে\n------------------------------\nInput:      ancholgulote\nActual:     অঞ্চলগুলোতে\nPrediction: অঞ্চলগুলোতে\n------------------------------\nInput:      oncholgoolote\nActual:     অঞ্চলগুলোতে\nPrediction: অঞ্চলগুলোতে\n------------------------------\nInput:      oncholgulote\nActual:     অঞ্চলগুলোতে\nPrediction: অঞ্চলগুলোতে\n------------------------------\nInput:      anchalti\nActual:     অঞ্চলটি\nPrediction: অঞ্চলতি\n------------------------------\nInput:      ancholtee\nActual:     অঞ্চলটি\nPrediction: অঞ্চলদে\n------------------------------\nInput:      ancholti\nActual:     অঞ্চলটি\nPrediction: অঞ্চলতি\n------------------------------\nInput:      onchalti\nActual:     অঞ্চলটি\nPrediction: অঞ্চলতি\n------------------------------\nInput:      oncholtee\nActual:     অঞ্চলটি\nPrediction: অনচলিতে\n------------------------------\nInput:      oncholti\nActual:     অঞ্চলটি\nPrediction: অঞ্চলতি\n------------------------------\nInput:      anchaltike\nActual:     অঞ্চলটিকে\nPrediction: অঞ্চলতিকে\n------------------------------\nInput:      anchaltikey\nActual:     অঞ্চলটিকে\nPrediction: অঞ্চলতিকে\n------------------------------\nInput:      ancholtike\nActual:     অঞ্চলটিকে\nPrediction: অঞ্চলতিকে\n------------------------------\nInput:      ancholtikey\nActual:     অঞ্চলটিকে\nPrediction: অঞ্চলতিকে\n------------------------------\nInput:      oncoltike\nActual:     অঞ্চলটিকে\nPrediction: অনকালিতে\n------------------------------\nInput:      anchaltite\nActual:     অঞ্চলটিতে\nPrediction: অঞ্চলতিতে\n------------------------------\nInput:      anchaltitey\nActual:     অঞ্চলটিতে\nPrediction: অঞ্চলতিতে\n------------------------------\nInput:      ancholtite\nActual:     অঞ্চলটিতে\nPrediction: অঞ্চলতিতে\n------------------------------\nInput:      ancholtitey\nActual:     অঞ্চলটিতে\nPrediction: অঞ্চলতিতে\n------------------------------\nInput:      oncholtite\nActual:     অঞ্চলটিতে\nPrediction: অঞ্চলতিতে\n------------------------------\nInput:      anchalsamuha\nActual:     অঞ্চলসমূহ\nPrediction: অঞ্চমভালো\n------------------------------\nInput:      anchalsamuho\nActual:     অঞ্চলসমূহ\nPrediction: অঞ্চমূলসা\n------------------------------\nSaved predictions to beam_search_predictions.csv\n",
          "output_type": "stream"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": ""
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁</td></tr><tr><td>test_accuracy</td><td>▁</td></tr><tr><td>test_loss</td><td>▁</td></tr><tr><td>test_word_accuracy</td><td>▁</td></tr><tr><td>train_accuracy</td><td>▁</td></tr><tr><td>train_loss</td><td>▁</td></tr><tr><td>train_word_accuracy</td><td>▁</td></tr><tr><td>val_accuracy</td><td>▁</td></tr><tr><td>val_loss</td><td>▁</td></tr><tr><td>val_word_accuracy</td><td>▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>1</td></tr><tr><td>test_accuracy</td><td>76.95625</td></tr><tr><td>test_loss</td><td>0.71495</td></tr><tr><td>test_word_accuracy</td><td>16.62702</td></tr><tr><td>train_accuracy</td><td>58.07133</td></tr><tr><td>train_loss</td><td>1.4595</td></tr><tr><td>train_word_accuracy</td><td>6.58488</td></tr><tr><td>val_accuracy</td><td>77.33357</td></tr><tr><td>val_loss</td><td>0.71883</td></tr><tr><td>val_word_accuracy</td><td>17.24242</td></tr></table><br/></div></div>"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": " View run <strong style=\"color:#cdcd00\">earnest-sweep-1</strong> at: <a href='https://wandb.ai/ma23m011-iit-madras/DL_A3/runs/0wxhv9b3' target=\"_blank\">https://wandb.ai/ma23m011-iit-madras/DL_A3/runs/0wxhv9b3</a><br> View project at: <a href='https://wandb.ai/ma23m011-iit-madras/DL_A3' target=\"_blank\">https://wandb.ai/ma23m011-iit-madras/DL_A3</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": "<IPython.core.display.HTML object>",
            "text/html": "Find logs at: <code>./wandb/run-20250520_140559-0wxhv9b3/logs</code>"
          },
          "metadata": {}
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "trusted": true,
        "id": "9iNYsJK2VXiY"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}